{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrXCvRKynZEz",
        "outputId": "b1509ffd-bce0-4c2a-fbdd-60b003853827"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Unzipping /content/drive/MyDrive/my_clean_cropped_data_splitted_and_resized.zip to /content/dataset...\n",
            "Extraction complete.\n",
            "\n",
            "SPLIT                CLASS           COUNT     \n",
            "---------------------------------------------\n",
            "val                  surprised       8         \n",
            "val                  sad             20        \n",
            "val                  angry           12        \n",
            "val                  happy           32        \n",
            "val                  fear            23        \n",
            "train_balanced_aug   surprised       200       \n",
            "train_balanced_aug   sad             200       \n",
            "train_balanced_aug   angry           200       \n",
            "train_balanced_aug   happy           200       \n",
            "train_balanced_aug   fear            200       \n",
            "test                 surprised       8         \n",
            "test                 sad             20        \n",
            "test                 angry           12        \n",
            "test                 happy           32        \n",
            "test                 fear            23        \n",
            "---------------------------------------------\n",
            "TOTAL IMAGES FOUND: 1190\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import zipfile\n",
        "from google.colab import drive\n",
        "\n",
        "# --- 1. MOUNT DRIVE ---\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# --- 2. SETUP PATHS ---\n",
        "# Verify this path matches your Drive exactly\n",
        "zip_path = '/content/drive/MyDrive/my_clean_cropped_data_splitted_and_resized.zip'\n",
        "extract_path = '/content/dataset'\n",
        "\n",
        "# --- 3. EXTRACT (Force Overwrite to ensure fresh start) ---\n",
        "print(f\"Unzipping {zip_path} to {extract_path}...\")\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "print(\"Extraction complete.\\n\")\n",
        "\n",
        "# --- 4. RUTHLESS AUDIT ---\n",
        "# We need to know EXACTLY what we are working with.\n",
        "base_dir = os.path.join(extract_path, 'my_clean_cropped_data_splitted_and_resized')\n",
        "\n",
        "if not os.path.exists(base_dir):\n",
        "    print(f\"CRITICAL ERROR: Directory {base_dir} not found. Check your zip file structure.\")\n",
        "else:\n",
        "    print(f\"{'SPLIT':<20} {'CLASS':<15} {'COUNT':<10}\")\n",
        "    print(\"-\" * 45)\n",
        "\n",
        "    total_images = 0\n",
        "    # Walk through Test and Train folders\n",
        "    for split in os.listdir(base_dir):\n",
        "        split_path = os.path.join(base_dir, split)\n",
        "        if os.path.isdir(split_path):\n",
        "            for class_name in os.listdir(split_path):\n",
        "                class_path = os.path.join(split_path, class_name)\n",
        "                if os.path.isdir(class_path):\n",
        "                    count = len(os.listdir(class_path))\n",
        "                    print(f\"{split:<20} {class_name:<15} {count:<10}\")\n",
        "                    total_images += count\n",
        "\n",
        "    print(\"-\" * 45)\n",
        "    print(f\"TOTAL IMAGES FOUND: {total_images}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# --- 1. CONFIGURATION ---\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 40  # Set high, EarlyStopping will cut it short\n",
        "LR = 1e-4    # Low learning rate for fine-tuning\n",
        "\n",
        "# --- 2. DATA LOADERS (With MobileNet Preprocessing) ---\n",
        "# Note: We do NOT augment validation/test data, only rescale.\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,\n",
        "    # Add slight on-the-fly augmentation just to be safe\n",
        "    rotation_range=20,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "val_test_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input\n",
        ")\n",
        "\n",
        "# Load Data\n",
        "train_ds = train_datagen.flow_from_directory(\n",
        "    '/content/dataset/my_clean_cropped_data_splitted_and_resized/train_balanced_aug',\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_ds = val_test_datagen.flow_from_directory(\n",
        "    '/content/dataset/my_clean_cropped_data_splitted_and_resized/val',\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False # Don't shuffle val/test for consistency\n",
        ")\n",
        "\n",
        "test_ds = val_test_datagen.flow_from_directory(\n",
        "    '/content/dataset/my_clean_cropped_data_splitted_and_resized/test',\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# --- 3. BUILD BASELINE MOBILENETV2 ---\n",
        "def build_baseline_mobilenet():\n",
        "    base_model = MobileNetV2(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
        "    )\n",
        "\n",
        "    # Freeze base model initially?\n",
        "    # For small datasets, better to unfreeze top layers or train all with low LR.\n",
        "    # We will Train ALL with very low LR for best performance.\n",
        "    base_model.trainable = True\n",
        "\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dropout(0.5)(x) # Simple regularization\n",
        "    outputs = Dense(5, activation='softmax')(x) # 5 Classes\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "model = build_baseline_mobilenet()\n",
        "\n",
        "# --- 4. COMPILE & TRAIN ---\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=LR),\n",
        "    loss='categorical_crossentropy', # Standard Loss (No Weights)\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
        "]\n",
        "\n",
        "print(\"Starting Baseline Training...\")\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "# --- 5. EVALUATE ---\n",
        "print(\"\\n--- FINAL TEST EVALUATION ---\")\n",
        "loss, acc = model.evaluate(test_ds)\n",
        "print(f\"Baseline MobileNetV2 Accuracy: {acc*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imweN5XoqzRa",
        "outputId": "0b437ff4-3d16-426c-f772-26af6895efaa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1000 images belonging to 5 classes.\n",
            "Found 95 images belonging to 5 classes.\n",
            "Found 95 images belonging to 5 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Starting Baseline Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 2s/step - accuracy: 0.3857 - loss: 1.5698 - val_accuracy: 0.3789 - val_loss: 1.6863 - learning_rate: 1.0000e-04\n",
            "Epoch 2/40\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 397ms/step - accuracy: 0.8198 - loss: 0.5238 - val_accuracy: 0.4842 - val_loss: 1.3091 - learning_rate: 1.0000e-04\n",
            "Epoch 3/40\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 390ms/step - accuracy: 0.9319 - loss: 0.2515 - val_accuracy: 0.5368 - val_loss: 1.0554 - learning_rate: 1.0000e-04\n",
            "Epoch 4/40\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 393ms/step - accuracy: 0.9597 - loss: 0.1511 - val_accuracy: 0.5368 - val_loss: 1.0022 - learning_rate: 1.0000e-04\n",
            "Epoch 5/40\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 390ms/step - accuracy: 0.9873 - loss: 0.0764 - val_accuracy: 0.5579 - val_loss: 1.0182 - learning_rate: 1.0000e-04\n",
            "Epoch 6/40\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 394ms/step - accuracy: 0.9899 - loss: 0.0566 - val_accuracy: 0.6632 - val_loss: 0.8866 - learning_rate: 1.0000e-04\n",
            "Epoch 7/40\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 389ms/step - accuracy: 0.9950 - loss: 0.0364 - val_accuracy: 0.6737 - val_loss: 0.8230 - learning_rate: 1.0000e-04\n",
            "Epoch 8/40\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 388ms/step - accuracy: 0.9904 - loss: 0.0379 - val_accuracy: 0.6211 - val_loss: 0.8361 - learning_rate: 1.0000e-04\n",
            "Epoch 9/40\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 390ms/step - accuracy: 0.9950 - loss: 0.0239 - val_accuracy: 0.7053 - val_loss: 0.8335 - learning_rate: 1.0000e-04\n",
            "Epoch 10/40\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 389ms/step - accuracy: 0.9959 - loss: 0.0174 - val_accuracy: 0.7263 - val_loss: 0.7146 - learning_rate: 1.0000e-04\n",
            "Epoch 11/40\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 364ms/step - accuracy: 0.9878 - loss: 0.0309 - val_accuracy: 0.7474 - val_loss: 0.7270 - learning_rate: 1.0000e-04\n",
            "Epoch 12/40\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 392ms/step - accuracy: 0.9977 - loss: 0.0104 - val_accuracy: 0.7474 - val_loss: 0.7056 - learning_rate: 1.0000e-04\n",
            "Epoch 13/40\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 389ms/step - accuracy: 0.9995 - loss: 0.0068 - val_accuracy: 0.7579 - val_loss: 0.5897 - learning_rate: 1.0000e-04\n",
            "Epoch 14/40\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 392ms/step - accuracy: 0.9997 - loss: 0.0095 - val_accuracy: 0.8316 - val_loss: 0.5143 - learning_rate: 1.0000e-04\n",
            "Epoch 15/40\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 393ms/step - accuracy: 0.9997 - loss: 0.0066 - val_accuracy: 0.8211 - val_loss: 0.5041 - learning_rate: 1.0000e-04\n",
            "Epoch 16/40\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 394ms/step - accuracy: 1.0000 - loss: 0.0073 - val_accuracy: 0.8211 - val_loss: 0.5150 - learning_rate: 1.0000e-04\n",
            "Epoch 17/40\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 390ms/step - accuracy: 0.9995 - loss: 0.0081 - val_accuracy: 0.8421 - val_loss: 0.4631 - learning_rate: 1.0000e-04\n",
            "Epoch 18/40\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 389ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.8105 - val_loss: 0.5126 - learning_rate: 1.0000e-04\n",
            "Epoch 19/40\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 389ms/step - accuracy: 0.9998 - loss: 0.0048 - val_accuracy: 0.8421 - val_loss: 0.4282 - learning_rate: 1.0000e-04\n",
            "Epoch 20/40\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 390ms/step - accuracy: 0.9989 - loss: 0.0036 - val_accuracy: 0.8842 - val_loss: 0.3679 - learning_rate: 1.0000e-04\n",
            "Epoch 21/40\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 389ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.8526 - val_loss: 0.4088 - learning_rate: 1.0000e-04\n",
            "Epoch 22/40\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 377ms/step - accuracy: 0.9988 - loss: 0.0032 - val_accuracy: 0.8316 - val_loss: 0.4342 - learning_rate: 1.0000e-04\n",
            "Epoch 23/40\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step - accuracy: 1.0000 - loss: 0.0032\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 392ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.8421 - val_loss: 0.3812 - learning_rate: 1.0000e-04\n",
            "Epoch 24/40\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 394ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.8526 - val_loss: 0.3537 - learning_rate: 5.0000e-05\n",
            "Epoch 25/40\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 393ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.8947 - val_loss: 0.3067 - learning_rate: 5.0000e-05\n",
            "Epoch 26/40\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 387ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.8947 - val_loss: 0.2705 - learning_rate: 5.0000e-05\n",
            "Epoch 27/40\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 394ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.9158 - val_loss: 0.2338 - learning_rate: 5.0000e-05\n",
            "Epoch 28/40\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 390ms/step - accuracy: 0.9993 - loss: 0.0033 - val_accuracy: 0.9158 - val_loss: 0.2222 - learning_rate: 5.0000e-05\n",
            "Epoch 29/40\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 389ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9263 - val_loss: 0.2088 - learning_rate: 5.0000e-05\n",
            "Epoch 30/40\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 393ms/step - accuracy: 0.9961 - loss: 0.0048 - val_accuracy: 0.9263 - val_loss: 0.2077 - learning_rate: 5.0000e-05\n",
            "Epoch 31/40\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 392ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9263 - val_loss: 0.2005 - learning_rate: 5.0000e-05\n",
            "Epoch 32/40\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 392ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9263 - val_loss: 0.2065 - learning_rate: 5.0000e-05\n",
            "Epoch 33/40\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 387ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9158 - val_loss: 0.1954 - learning_rate: 5.0000e-05\n",
            "Epoch 34/40\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 371ms/step - accuracy: 0.9985 - loss: 0.0047 - val_accuracy: 0.8632 - val_loss: 0.3846 - learning_rate: 5.0000e-05\n",
            "Epoch 35/40\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 356ms/step - accuracy: 0.9968 - loss: 0.0048 - val_accuracy: 0.8842 - val_loss: 0.2549 - learning_rate: 5.0000e-05\n",
            "Epoch 36/40\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364ms/step - accuracy: 0.9981 - loss: 0.0045\n",
            "Epoch 36: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 371ms/step - accuracy: 0.9982 - loss: 0.0044 - val_accuracy: 0.8737 - val_loss: 0.2489 - learning_rate: 5.0000e-05\n",
            "Epoch 37/40\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 389ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.8842 - val_loss: 0.2530 - learning_rate: 2.5000e-05\n",
            "Epoch 38/40\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 389ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.9053 - val_loss: 0.2439 - learning_rate: 2.5000e-05\n",
            "Epoch 39/40\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - accuracy: 1.0000 - loss: 0.0013\n",
            "Epoch 39: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 390ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9053 - val_loss: 0.2429 - learning_rate: 2.5000e-05\n",
            "Epoch 40/40\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 389ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.9263 - val_loss: 0.2158 - learning_rate: 1.2500e-05\n",
            "\n",
            "--- FINAL TEST EVALUATION ---\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9411 - loss: 0.2206\n",
            "Baseline MobileNetV2 Accuracy: 93.68%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save to the mounted Drive path\n",
        "save_path = '/content/drive/MyDrive/mobilenet_baseline_best.h5'\n",
        "model.save(save_path)\n",
        "print(f\"Model saved to {save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwUbtDjprQUK",
        "outputId": "05ec8ef3-0e95-48a9-fb25-258261267ce9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/drive/MyDrive/mobilenet_baseline_best.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MobileV2 with coordinate attention"
      ],
      "metadata": {
        "id": "yap8PoEbwWTM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, backend as K\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras import mixed_precision\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# --- 1. ENABLE MIXED PRECISION (Speed Hack) ---\n",
        "policy = mixed_precision.Policy('mixed_float16')\n",
        "mixed_precision.set_global_policy(policy)\n",
        "\n",
        "# --- 2. FAST DATA PIPELINE (Partner's Idea + Fixes) ---\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "# Define Paths\n",
        "base_dir = '/content/dataset/my_clean_cropped_data_splitted_and_resized'\n",
        "train_dir = os.path.join(base_dir, 'train_balanced_aug')\n",
        "val_dir = os.path.join(base_dir, 'val')\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "\n",
        "# Load Datasets (Using 'categorical' to match our loss function)\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_dir, image_size=IMG_SIZE, batch_size=BATCH_SIZE, label_mode='categorical', shuffle=True, seed=42\n",
        ")\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    val_dir, image_size=IMG_SIZE, batch_size=BATCH_SIZE, label_mode='categorical', shuffle=False\n",
        ")\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    test_dir, image_size=IMG_SIZE, batch_size=BATCH_SIZE, label_mode='categorical', shuffle=False\n",
        ")\n",
        "\n",
        "# Augmentation Block (Runs on GPU)\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.RandomZoom(0.1),\n",
        "])\n",
        "\n",
        "# Preprocessing Function (CORRECT MobileNet Scaling: -1 to 1)\n",
        "def preprocess(images, labels):\n",
        "    # tf.keras.applications.mobilenet_v2.preprocess_input expects [0, 255]\n",
        "    # It converts to [-1, 1] automatically.\n",
        "    return tf.keras.applications.mobilenet_v2.preprocess_input(images), labels\n",
        "\n",
        "def preprocess_train(images, labels):\n",
        "    images = data_augmentation(images)\n",
        "    return preprocess(images, labels)\n",
        "\n",
        "# Optimization (Cache & Prefetch)\n",
        "train_ds = train_ds.map(preprocess_train, num_parallel_calls=AUTOTUNE).cache().prefetch(AUTOTUNE)\n",
        "val_ds = val_ds.map(preprocess, num_parallel_calls=AUTOTUNE).cache().prefetch(AUTOTUNE)\n",
        "test_ds = test_ds.map(preprocess, num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)\n",
        "\n",
        "# --- 3. RE-DEFINE COORDINATE ATTENTION ---\n",
        "class CoordinateAttention(layers.Layer):\n",
        "    def __init__(self, reduction_ratio=32, **kwargs):\n",
        "        super(CoordinateAttention, self).__init__(**kwargs)\n",
        "        self.reduction_ratio = reduction_ratio\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        channels = input_shape[-1]\n",
        "        reduction_channels = max(8, channels // self.reduction_ratio)\n",
        "        self.conv_reduction = layers.Conv2D(reduction_channels, kernel_size=1, use_bias=False)\n",
        "        self.bn = layers.BatchNormalization()\n",
        "        self.activation = layers.Activation('relu')\n",
        "        self.conv_w = layers.Conv2D(channels, kernel_size=1, use_bias=False)\n",
        "        self.conv_h = layers.Conv2D(channels, kernel_size=1, use_bias=False)\n",
        "        super(CoordinateAttention, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        shape = tf.shape(inputs)\n",
        "        h, w, c = shape[1], shape[2], shape[3]\n",
        "        x_h = tf.reduce_mean(inputs, axis=2, keepdims=True)\n",
        "        x_w = tf.reduce_mean(inputs, axis=1, keepdims=True)\n",
        "        x_w_perm = tf.transpose(x_w, perm=[0, 2, 1, 3])\n",
        "        x_cat = tf.concat([x_h, x_w_perm], axis=1)\n",
        "        x_cat = self.conv_reduction(x_cat)\n",
        "        x_cat = self.bn(x_cat)\n",
        "        x_cat = self.activation(x_cat)\n",
        "        x_h_prime, x_w_prime = tf.split(x_cat, num_or_size_splits=[h, w], axis=1)\n",
        "        x_w_prime = tf.transpose(x_w_prime, perm=[0, 2, 1, 3])\n",
        "        att_h = tf.nn.sigmoid(self.conv_w(x_h_prime))\n",
        "        att_w = tf.nn.sigmoid(self.conv_h(x_w_prime))\n",
        "        return inputs * att_h * att_w\n",
        "\n",
        "# --- 4. BUILD MODEL (Unfrozen + CoordAtt) ---\n",
        "def build_final_model():\n",
        "    base_model = tf.keras.applications.MobileNetV2(\n",
        "        weights='imagenet', include_top=False, input_shape=(224, 224, 3)\n",
        "    )\n",
        "    base_model.trainable = True # CRITICAL: Must be True to learn emotions\n",
        "\n",
        "    inputs = tf.keras.Input(shape=(224, 224, 3))\n",
        "    x = base_model(inputs)\n",
        "    x = CoordinateAttention(reduction_ratio=32)(x) # The Novelty\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(5, activation='softmax', dtype='float32')(x)\n",
        "\n",
        "    return models.Model(inputs, outputs, name=\"PRDA_MobileNetV2_Final\")\n",
        "\n",
        "model = build_final_model()\n",
        "\n",
        "# --- 5. COMPILE & TRAIN ---\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=12, restore_best_weights=True),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, verbose=1),\n",
        "    ModelCheckpoint('/content/drive/MyDrive/prda_mobilenetv2_final.h5',\n",
        "                    monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)\n",
        "]\n",
        "\n",
        "print(\"Starting FINAL Training (Fast Pipe + CoordAtt + Unfrozen)...\")\n",
        "history = model.fit(train_ds, validation_data=val_ds, epochs=60, callbacks=callbacks)\n",
        "\n",
        "# --- 6. METRICS ---\n",
        "print(\"\\n--- GENERATING FINAL REPORT ---\")\n",
        "Y_pred = model.predict(test_ds)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "y_true = np.concatenate([y for x, y in test_ds], axis=0) # Extract labels from dataset\n",
        "y_true = np.argmax(y_true, axis=1)\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=['angry', 'fear', 'happy', 'sad', 'surprised']))\n",
        "\n",
        "final_acc = np.sum(y_pred == y_true) / len(y_true)\n",
        "print(f\"FINAL TEST ACCURACY: {final_acc*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6faUhJRuW1_",
        "outputId": "8ef38561-e9fa-4096-ca6d-e7ce3fdc8ab2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1000 files belonging to 5 classes.\n",
            "Found 95 files belonging to 5 classes.\n",
            "Found 95 files belonging to 5 classes.\n",
            "Starting FINAL Training (Fast Pipe + CoordAtt + Unfrozen)...\n",
            "Epoch 1/60\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.3658 - loss: 1.5084   \n",
            "Epoch 1: val_accuracy improved from -inf to 0.61053, saving model to /content/drive/MyDrive/prda_mobilenetv2_final.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 5s/step - accuracy: 0.3696 - loss: 1.5046 - val_accuracy: 0.6105 - val_loss: 1.4011 - learning_rate: 1.0000e-04\n",
            "Epoch 2/60\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9011 - loss: 0.7711\n",
            "Epoch 2: val_accuracy did not improve from 0.61053\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.9007 - loss: 0.7661 - val_accuracy: 0.6000 - val_loss: 1.1677 - learning_rate: 1.0000e-04\n",
            "Epoch 3/60\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9686 - loss: 0.3200\n",
            "Epoch 3: val_accuracy improved from 0.61053 to 0.63158, saving model to /content/drive/MyDrive/prda_mobilenetv2_final.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.9687 - loss: 0.3176 - val_accuracy: 0.6316 - val_loss: 0.9912 - learning_rate: 1.0000e-04\n",
            "Epoch 4/60\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9950 - loss: 0.1158\n",
            "Epoch 4: val_accuracy improved from 0.63158 to 0.67368, saving model to /content/drive/MyDrive/prda_mobilenetv2_final.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.9949 - loss: 0.1149 - val_accuracy: 0.6737 - val_loss: 0.8832 - learning_rate: 1.0000e-04\n",
            "Epoch 5/60\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9997 - loss: 0.0458\n",
            "Epoch 5: val_accuracy improved from 0.67368 to 0.70526, saving model to /content/drive/MyDrive/prda_mobilenetv2_final.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.9997 - loss: 0.0456 - val_accuracy: 0.7053 - val_loss: 0.8336 - learning_rate: 1.0000e-04\n",
            "Epoch 6/60\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.0246\n",
            "Epoch 6: val_accuracy did not improve from 0.70526\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.0245 - val_accuracy: 0.7053 - val_loss: 0.8042 - learning_rate: 1.0000e-04\n",
            "Epoch 7/60\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.0165\n",
            "Epoch 7: val_accuracy improved from 0.70526 to 0.72632, saving model to /content/drive/MyDrive/prda_mobilenetv2_final.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 0.0165 - val_accuracy: 0.7263 - val_loss: 0.7665 - learning_rate: 1.0000e-04\n",
            "Epoch 8/60\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0118\n",
            "Epoch 8: val_accuracy did not improve from 0.72632\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0117 - val_accuracy: 0.7263 - val_loss: 0.7358 - learning_rate: 1.0000e-04\n",
            "Epoch 9/60\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.0086\n",
            "Epoch 9: val_accuracy did not improve from 0.72632\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.0086 - val_accuracy: 0.7158 - val_loss: 0.7013 - learning_rate: 1.0000e-04\n",
            "Epoch 10/60\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.0070\n",
            "Epoch 10: val_accuracy did not improve from 0.72632\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 0.7158 - val_loss: 0.6737 - learning_rate: 1.0000e-04\n",
            "Epoch 11/60\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.0058\n",
            "Epoch 11: val_accuracy did not improve from 0.72632\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0059 - val_accuracy: 0.7158 - val_loss: 0.6446 - learning_rate: 1.0000e-04\n",
            "Epoch 12/60\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.0049\n",
            "Epoch 12: val_accuracy did not improve from 0.72632\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.7053 - val_loss: 0.6208 - learning_rate: 1.0000e-04\n",
            "Epoch 13/60\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.0041\n",
            "Epoch 13: val_accuracy did not improve from 0.72632\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.7158 - val_loss: 0.5917 - learning_rate: 1.0000e-04\n",
            "Epoch 14/60\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.0034\n",
            "Epoch 14: val_accuracy did not improve from 0.72632\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.7158 - val_loss: 0.5617 - learning_rate: 1.0000e-04\n",
            "Epoch 15/60\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0032\n",
            "Epoch 15: val_accuracy improved from 0.72632 to 0.76842, saving model to /content/drive/MyDrive/prda_mobilenetv2_final.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 114ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.7684 - val_loss: 0.5342 - learning_rate: 1.0000e-04\n",
            "Epoch 16/60\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.0026\n",
            "Epoch 16: val_accuracy improved from 0.76842 to 0.80000, saving model to /content/drive/MyDrive/prda_mobilenetv2_final.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.8000 - val_loss: 0.5089 - learning_rate: 1.0000e-04\n",
            "Epoch 17/60\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.0024\n",
            "Epoch 17: val_accuracy improved from 0.80000 to 0.82105, saving model to /content/drive/MyDrive/prda_mobilenetv2_final.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.8211 - val_loss: 0.4841 - learning_rate: 1.0000e-04\n",
            "Epoch 18/60\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.0021\n",
            "Epoch 18: val_accuracy improved from 0.82105 to 0.83158, saving model to /content/drive/MyDrive/prda_mobilenetv2_final.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.8316 - val_loss: 0.4622 - learning_rate: 1.0000e-04\n",
            "Epoch 19/60\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.0020\n",
            "Epoch 19: val_accuracy improved from 0.83158 to 0.85263, saving model to /content/drive/MyDrive/prda_mobilenetv2_final.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.8526 - val_loss: 0.4412 - learning_rate: 1.0000e-04\n",
            "Epoch 20/60\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0018\n",
            "Epoch 20: val_accuracy improved from 0.85263 to 0.86316, saving model to /content/drive/MyDrive/prda_mobilenetv2_final.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.8632 - val_loss: 0.4153 - learning_rate: 1.0000e-04\n",
            "Epoch 21/60\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.0016\n",
            "Epoch 21: val_accuracy improved from 0.86316 to 0.87368, saving model to /content/drive/MyDrive/prda_mobilenetv2_final.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.8737 - val_loss: 0.3916 - learning_rate: 1.0000e-04\n",
            "Epoch 22/60\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.0015\n",
            "Epoch 22: val_accuracy did not improve from 0.87368\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.8737 - val_loss: 0.3709 - learning_rate: 1.0000e-04\n",
            "Epoch 23/60\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.0014\n",
            "Epoch 23: val_accuracy did not improve from 0.87368\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.8737 - val_loss: 0.3498 - learning_rate: 1.0000e-04\n",
            "Epoch 24/60\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.0013\n",
            "Epoch 24: val_accuracy did not improve from 0.87368\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.8737 - val_loss: 0.3325 - learning_rate: 1.0000e-04\n",
            "Epoch 25/60\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.0012\n",
            "Epoch 25: val_accuracy improved from 0.87368 to 0.88421, saving model to /content/drive/MyDrive/prda_mobilenetv2_final.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.8842 - val_loss: 0.3129 - learning_rate: 1.0000e-04\n",
            "Epoch 26/60\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0011\n",
            "Epoch 26: val_accuracy did not improve from 0.88421\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.8842 - val_loss: 0.2980 - learning_rate: 1.0000e-04\n",
            "Epoch 27/60\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 9.8636e-04\n",
            "Epoch 27: val_accuracy did not improve from 0.88421\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 9.8653e-04 - val_accuracy: 0.8842 - val_loss: 0.2895 - learning_rate: 1.0000e-04\n",
            "Epoch 28/60\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 9.7074e-04\n",
            "Epoch 28: val_accuracy did not improve from 0.88421\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 9.7077e-04 - val_accuracy: 0.8842 - val_loss: 0.2794 - learning_rate: 1.0000e-04\n",
            "Epoch 29/60\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 9.1714e-04\n",
            "Epoch 29: val_accuracy improved from 0.88421 to 0.89474, saving model to /content/drive/MyDrive/prda_mobilenetv2_final.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - accuracy: 1.0000 - loss: 9.1616e-04 - val_accuracy: 0.8947 - val_loss: 0.2694 - learning_rate: 1.0000e-04\n",
            "Epoch 30/60\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 8.6238e-04\n",
            "Epoch 30: val_accuracy did not improve from 0.89474\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 8.6093e-04 - val_accuracy: 0.8842 - val_loss: 0.2605 - learning_rate: 1.0000e-04\n",
            "Epoch 31/60\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 8.2805e-04\n",
            "Epoch 31: val_accuracy did not improve from 0.89474\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 8.2721e-04 - val_accuracy: 0.8737 - val_loss: 0.2530 - learning_rate: 1.0000e-04\n",
            "Epoch 32/60\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 7.6101e-04\n",
            "Epoch 32: val_accuracy did not improve from 0.89474\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 7.6145e-04 - val_accuracy: 0.8842 - val_loss: 0.2497 - learning_rate: 1.0000e-04\n",
            "Epoch 33/60\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 6.6482e-04\n",
            "Epoch 33: val_accuracy did not improve from 0.89474\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 6.6531e-04 - val_accuracy: 0.8947 - val_loss: 0.2442 - learning_rate: 1.0000e-04\n",
            "Epoch 34/60\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 6.2606e-04\n",
            "Epoch 34: val_accuracy did not improve from 0.89474\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 6.2571e-04 - val_accuracy: 0.8947 - val_loss: 0.2400 - learning_rate: 1.0000e-04\n",
            "Epoch 35/60\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 6.5419e-04\n",
            "Epoch 35: val_accuracy did not improve from 0.89474\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 6.5367e-04 - val_accuracy: 0.8947 - val_loss: 0.2354 - learning_rate: 1.0000e-04\n",
            "Epoch 36/60\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 6.2036e-04\n",
            "Epoch 36: val_accuracy did not improve from 0.89474\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 6.2003e-04 - val_accuracy: 0.8947 - val_loss: 0.2307 - learning_rate: 1.0000e-04\n",
            "Epoch 37/60\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 5.6453e-04\n",
            "Epoch 37: val_accuracy did not improve from 0.89474\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 5.6356e-04 - val_accuracy: 0.8947 - val_loss: 0.2281 - learning_rate: 1.0000e-04\n",
            "Epoch 38/60\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 5.4515e-04\n",
            "Epoch 38: val_accuracy did not improve from 0.89474\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 5.4541e-04 - val_accuracy: 0.8947 - val_loss: 0.2259 - learning_rate: 1.0000e-04\n",
            "Epoch 39/60\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 4.9970e-04\n",
            "Epoch 39: val_accuracy did not improve from 0.89474\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 5.0056e-04 - val_accuracy: 0.8947 - val_loss: 0.2231 - learning_rate: 1.0000e-04\n",
            "Epoch 40/60\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 4.8118e-04\n",
            "Epoch 40: val_accuracy did not improve from 0.89474\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 4.8065e-04 - val_accuracy: 0.8947 - val_loss: 0.2189 - learning_rate: 1.0000e-04\n",
            "Epoch 41/60\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 4.3647e-04\n",
            "Epoch 41: val_accuracy did not improve from 0.89474\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 4.3647e-04 - val_accuracy: 0.8947 - val_loss: 0.2191 - learning_rate: 1.0000e-04\n",
            "Epoch 42/60\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 4.3920e-04\n",
            "Epoch 42: val_accuracy improved from 0.89474 to 0.90526, saving model to /content/drive/MyDrive/prda_mobilenetv2_final.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 102ms/step - accuracy: 1.0000 - loss: 4.3935e-04 - val_accuracy: 0.9053 - val_loss: 0.2181 - learning_rate: 1.0000e-04\n",
            "Epoch 43/60\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 3.9655e-04\n",
            "Epoch 43: val_accuracy did not improve from 0.90526\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 3.9722e-04 - val_accuracy: 0.9053 - val_loss: 0.2164 - learning_rate: 1.0000e-04\n",
            "Epoch 44/60\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 3.9413e-04\n",
            "Epoch 44: val_accuracy did not improve from 0.90526\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 3.9449e-04 - val_accuracy: 0.9053 - val_loss: 0.2153 - learning_rate: 1.0000e-04\n",
            "Epoch 45/60\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 3.9544e-04\n",
            "Epoch 45: val_accuracy improved from 0.90526 to 0.91579, saving model to /content/drive/MyDrive/prda_mobilenetv2_final.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 3.9541e-04 - val_accuracy: 0.9158 - val_loss: 0.2130 - learning_rate: 1.0000e-04\n",
            "Epoch 46/60\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 3.7918e-04\n",
            "Epoch 46: val_accuracy did not improve from 0.91579\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 3.7861e-04 - val_accuracy: 0.9158 - val_loss: 0.2126 - learning_rate: 1.0000e-04\n",
            "Epoch 47/60\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 3.6252e-04\n",
            "Epoch 47: val_accuracy did not improve from 0.91579\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 3.6129e-04 - val_accuracy: 0.9158 - val_loss: 0.2124 - learning_rate: 1.0000e-04\n",
            "Epoch 48/60\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 3.4110e-04\n",
            "Epoch 48: val_accuracy improved from 0.91579 to 0.92632, saving model to /content/drive/MyDrive/prda_mobilenetv2_final.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 3.4106e-04 - val_accuracy: 0.9263 - val_loss: 0.2114 - learning_rate: 1.0000e-04\n",
            "Epoch 49/60\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 3.0190e-04\n",
            "Epoch 49: val_accuracy did not improve from 0.92632\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 3.0341e-04 - val_accuracy: 0.9158 - val_loss: 0.2106 - learning_rate: 1.0000e-04\n",
            "Epoch 50/60\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 3.1155e-04\n",
            "Epoch 50: val_accuracy did not improve from 0.92632\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 3.1174e-04 - val_accuracy: 0.9158 - val_loss: 0.2084 - learning_rate: 1.0000e-04\n",
            "Epoch 51/60\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 3.1280e-04\n",
            "Epoch 51: val_accuracy did not improve from 0.92632\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 3.1259e-04 - val_accuracy: 0.9158 - val_loss: 0.2071 - learning_rate: 1.0000e-04\n",
            "Epoch 52/60\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 2.9628e-04\n",
            "Epoch 52: val_accuracy did not improve from 0.92632\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 2.9622e-04 - val_accuracy: 0.9158 - val_loss: 0.2073 - learning_rate: 1.0000e-04\n",
            "Epoch 53/60\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 2.7162e-04\n",
            "Epoch 53: val_accuracy did not improve from 0.92632\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 2.7181e-04 - val_accuracy: 0.9158 - val_loss: 0.2087 - learning_rate: 1.0000e-04\n",
            "Epoch 54/60\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 2.6292e-04\n",
            "Epoch 54: val_accuracy did not improve from 0.92632\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 2.6266e-04 - val_accuracy: 0.9158 - val_loss: 0.2077 - learning_rate: 1.0000e-04\n",
            "Epoch 55/60\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 2.4707e-04\n",
            "Epoch 55: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\n",
            "Epoch 55: val_accuracy did not improve from 0.92632\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 2.4790e-04 - val_accuracy: 0.9158 - val_loss: 0.2075 - learning_rate: 1.0000e-04\n",
            "Epoch 56/60\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 2.3868e-04\n",
            "Epoch 56: val_accuracy did not improve from 0.92632\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 2.3957e-04 - val_accuracy: 0.9158 - val_loss: 0.2071 - learning_rate: 5.0000e-05\n",
            "Epoch 57/60\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 2.5946e-04\n",
            "Epoch 57: val_accuracy did not improve from 0.92632\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 2.5959e-04 - val_accuracy: 0.9158 - val_loss: 0.2076 - learning_rate: 5.0000e-05\n",
            "Epoch 58/60\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 2.4751e-04\n",
            "Epoch 58: val_accuracy did not improve from 0.92632\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 2.4720e-04 - val_accuracy: 0.9158 - val_loss: 0.2068 - learning_rate: 5.0000e-05\n",
            "Epoch 59/60\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 2.3770e-04\n",
            "Epoch 59: val_accuracy did not improve from 0.92632\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 2.3735e-04 - val_accuracy: 0.9158 - val_loss: 0.2056 - learning_rate: 5.0000e-05\n",
            "Epoch 60/60\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 2.3467e-04\n",
            "Epoch 60: val_accuracy did not improve from 0.92632\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 2.3477e-04 - val_accuracy: 0.9158 - val_loss: 0.2053 - learning_rate: 5.0000e-05\n",
            "\n",
            "--- GENERATING FINAL REPORT ---\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 6s/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       1.00      0.83      0.91        12\n",
            "        fear       0.95      0.91      0.93        23\n",
            "       happy       0.94      1.00      0.97        32\n",
            "         sad       0.95      1.00      0.98        20\n",
            "   surprised       0.88      0.88      0.88         8\n",
            "\n",
            "    accuracy                           0.95        95\n",
            "   macro avg       0.94      0.92      0.93        95\n",
            "weighted avg       0.95      0.95      0.95        95\n",
            "\n",
            "FINAL TEST ACCURACY: 94.74%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MobilenetV3"
      ],
      "metadata": {
        "id": "ow81QwH4wcFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, mixed_precision\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import numpy as np\n",
        "import os\n",
        "import zipfile\n",
        "from google.colab import drive\n",
        "\n",
        "# --- 1. SETUP & RECOVERY ---\n",
        "# Re-mount Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Paths\n",
        "zip_path = '/content/drive/MyDrive/my_clean_cropped_data_splitted_and_resized.zip'\n",
        "extract_path = '/content/dataset'\n",
        "base_dir = '/content/dataset/my_clean_cropped_data_splitted_and_resized'\n",
        "\n",
        "# Check if data exists, if not, unzip it\n",
        "if not os.path.exists(base_dir):\n",
        "    print(f\"Data not found. Unzipping {zip_path}...\")\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "    print(\"Unzipping complete.\")\n",
        "else:\n",
        "    print(\"Data already exists. Skipping unzip.\")\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'train_balanced_aug')\n",
        "val_dir = os.path.join(base_dir, 'val')\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "\n",
        "# --- 2. GPU SPEED HACK ---\n",
        "tf.keras.backend.clear_session() # clear old memory\n",
        "policy = mixed_precision.Policy('mixed_float16')\n",
        "mixed_precision.set_global_policy(policy)\n",
        "\n",
        "# --- 3. LOW RAM DATA PIPELINE ---\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "# Load Data\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_dir, image_size=IMG_SIZE, batch_size=BATCH_SIZE, label_mode='categorical', shuffle=True\n",
        ")\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    val_dir, image_size=IMG_SIZE, batch_size=BATCH_SIZE, label_mode='categorical', shuffle=False\n",
        ")\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    test_dir, image_size=IMG_SIZE, batch_size=BATCH_SIZE, label_mode='categorical', shuffle=False\n",
        ")\n",
        "\n",
        "# Augmentation\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.1),\n",
        "])\n",
        "\n",
        "def augment_only(images, labels):\n",
        "    return data_augmentation(images), labels\n",
        "\n",
        "# Optimize: Prefetch ONLY (No .cache() to save RAM)\n",
        "train_ds = train_ds.map(augment_only, num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)\n",
        "val_ds = val_ds.prefetch(AUTOTUNE)\n",
        "test_ds = test_ds.prefetch(AUTOTUNE)\n",
        "\n",
        "# --- 4. BUILD MODEL (V3 SAFE MODE) ---\n",
        "# Let Keras handle preprocessing internally\n",
        "def build_mobilenet_v3_safe():\n",
        "    base_model = tf.keras.applications.MobileNetV3Large(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        input_shape=(224, 224, 3),\n",
        "        include_preprocessing=True\n",
        "    )\n",
        "    base_model.trainable = True\n",
        "\n",
        "    inputs = tf.keras.Input(shape=(224, 224, 3))\n",
        "    x = base_model(inputs)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(5, activation='softmax', dtype='float32')(x)\n",
        "\n",
        "    return models.Model(inputs, outputs, name=\"Benchmark_MobileNetV3_Safe\")\n",
        "\n",
        "model = build_mobilenet_v3_safe()\n",
        "\n",
        "# --- 5. COMPILE & TRAIN ---\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), # Low LR for stability\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "    ModelCheckpoint('/content/drive/MyDrive/mobilenetv3_safe_best.h5',\n",
        "                    monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)\n",
        "]\n",
        "\n",
        "print(\"Starting V3 Training...\")\n",
        "history = model.fit(train_ds, validation_data=val_ds, epochs=50, callbacks=callbacks)\n",
        "\n",
        "# --- 6. REPORT ---\n",
        "loss, acc = model.evaluate(test_ds)\n",
        "print(f\"\\nFINAL V3 ACCURACY: {acc*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVR053XW0ZLP",
        "outputId": "5c8f6ea9-f577-4fc0-dbc1-3c52f7471389"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Data not found. Unzipping /content/drive/MyDrive/my_clean_cropped_data_splitted_and_resized.zip...\n",
            "Unzipping complete.\n",
            "Found 1000 files belonging to 5 classes.\n",
            "Found 95 files belonging to 5 classes.\n",
            "Found 95 files belonging to 5 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v3/weights_mobilenet_v3_large_224_1.0_float_no_top_v2.h5\n",
            "\u001b[1m12683000/12683000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Starting V3 Training...\n",
            "Epoch 1/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.2097 - loss: 2.2520   \n",
            "Epoch 1: val_accuracy improved from -inf to 0.08421, saving model to /content/drive/MyDrive/mobilenetv3_safe_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m365s\u001b[0m 6s/step - accuracy: 0.2094 - loss: 2.2518 - val_accuracy: 0.0842 - val_loss: 2.3427\n",
            "Epoch 2/50\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.2228 - loss: 2.0700\n",
            "Epoch 2: val_accuracy did not improve from 0.08421\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 195ms/step - accuracy: 0.2234 - loss: 2.0666 - val_accuracy: 0.0842 - val_loss: 2.2504\n",
            "Epoch 3/50\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - accuracy: 0.2906 - loss: 1.8394\n",
            "Epoch 3: val_accuracy improved from 0.08421 to 0.11579, saving model to /content/drive/MyDrive/mobilenetv3_safe_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 277ms/step - accuracy: 0.2901 - loss: 1.8397 - val_accuracy: 0.1158 - val_loss: 2.1672\n",
            "Epoch 4/50\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 0.3033 - loss: 1.7954\n",
            "Epoch 4: val_accuracy improved from 0.11579 to 0.13684, saving model to /content/drive/MyDrive/mobilenetv3_safe_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 268ms/step - accuracy: 0.3030 - loss: 1.7943 - val_accuracy: 0.1368 - val_loss: 2.0921\n",
            "Epoch 5/50\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.3472 - loss: 1.6412\n",
            "Epoch 5: val_accuracy did not improve from 0.13684\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 198ms/step - accuracy: 0.3474 - loss: 1.6409 - val_accuracy: 0.1368 - val_loss: 2.0233\n",
            "Epoch 6/50\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 0.3684 - loss: 1.5420\n",
            "Epoch 6: val_accuracy improved from 0.13684 to 0.14737, saving model to /content/drive/MyDrive/mobilenetv3_safe_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 303ms/step - accuracy: 0.3693 - loss: 1.5409 - val_accuracy: 0.1474 - val_loss: 1.9561\n",
            "Epoch 7/50\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - accuracy: 0.3817 - loss: 1.5106\n",
            "Epoch 7: val_accuracy improved from 0.14737 to 0.15789, saving model to /content/drive/MyDrive/mobilenetv3_safe_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 235ms/step - accuracy: 0.3832 - loss: 1.5083 - val_accuracy: 0.1579 - val_loss: 1.8887\n",
            "Epoch 8/50\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.4428 - loss: 1.4264\n",
            "Epoch 8: val_accuracy improved from 0.15789 to 0.22105, saving model to /content/drive/MyDrive/mobilenetv3_safe_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 251ms/step - accuracy: 0.4433 - loss: 1.4246 - val_accuracy: 0.2211 - val_loss: 1.8290\n",
            "Epoch 9/50\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 0.4824 - loss: 1.3468\n",
            "Epoch 9: val_accuracy improved from 0.22105 to 0.23158, saving model to /content/drive/MyDrive/mobilenetv3_safe_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 286ms/step - accuracy: 0.4826 - loss: 1.3453 - val_accuracy: 0.2316 - val_loss: 1.7697\n",
            "Epoch 10/50\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.5285 - loss: 1.1944\n",
            "Epoch 10: val_accuracy improved from 0.23158 to 0.26316, saving model to /content/drive/MyDrive/mobilenetv3_safe_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 249ms/step - accuracy: 0.5275 - loss: 1.1968 - val_accuracy: 0.2632 - val_loss: 1.7064\n",
            "Epoch 11/50\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.5593 - loss: 1.1428\n",
            "Epoch 11: val_accuracy improved from 0.26316 to 0.28421, saving model to /content/drive/MyDrive/mobilenetv3_safe_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 233ms/step - accuracy: 0.5579 - loss: 1.1442 - val_accuracy: 0.2842 - val_loss: 1.6405\n",
            "Epoch 12/50\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - accuracy: 0.5644 - loss: 1.0938\n",
            "Epoch 12: val_accuracy improved from 0.28421 to 0.33684, saving model to /content/drive/MyDrive/mobilenetv3_safe_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 264ms/step - accuracy: 0.5643 - loss: 1.0948 - val_accuracy: 0.3368 - val_loss: 1.5761\n",
            "Epoch 13/50\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 0.6140 - loss: 1.0476\n",
            "Epoch 13: val_accuracy improved from 0.33684 to 0.38947, saving model to /content/drive/MyDrive/mobilenetv3_safe_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 233ms/step - accuracy: 0.6143 - loss: 1.0466 - val_accuracy: 0.3895 - val_loss: 1.5099\n",
            "Epoch 14/50\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 0.6231 - loss: 1.0306\n",
            "Epoch 14: val_accuracy improved from 0.38947 to 0.42105, saving model to /content/drive/MyDrive/mobilenetv3_safe_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 263ms/step - accuracy: 0.6227 - loss: 1.0304 - val_accuracy: 0.4211 - val_loss: 1.4460\n",
            "Epoch 15/50\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - accuracy: 0.5969 - loss: 1.0522\n",
            "Epoch 15: val_accuracy improved from 0.42105 to 0.49474, saving model to /content/drive/MyDrive/mobilenetv3_safe_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 289ms/step - accuracy: 0.5970 - loss: 1.0488 - val_accuracy: 0.4947 - val_loss: 1.3826\n",
            "Epoch 16/50\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.6715 - loss: 0.9163\n",
            "Epoch 16: val_accuracy improved from 0.49474 to 0.54737, saving model to /content/drive/MyDrive/mobilenetv3_safe_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 216ms/step - accuracy: 0.6716 - loss: 0.9163 - val_accuracy: 0.5474 - val_loss: 1.3154\n",
            "Epoch 17/50\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 0.6805 - loss: 0.9100\n",
            "Epoch 17: val_accuracy improved from 0.54737 to 0.58947, saving model to /content/drive/MyDrive/mobilenetv3_safe_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 282ms/step - accuracy: 0.6811 - loss: 0.9077 - val_accuracy: 0.5895 - val_loss: 1.2489\n",
            "Epoch 18/50\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 0.7206 - loss: 0.7697\n",
            "Epoch 18: val_accuracy improved from 0.58947 to 0.63158, saving model to /content/drive/MyDrive/mobilenetv3_safe_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 228ms/step - accuracy: 0.7205 - loss: 0.7708 - val_accuracy: 0.6316 - val_loss: 1.1828\n",
            "Epoch 19/50\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 0.6735 - loss: 0.8547\n",
            "Epoch 19: val_accuracy improved from 0.63158 to 0.66316, saving model to /content/drive/MyDrive/mobilenetv3_safe_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 233ms/step - accuracy: 0.6751 - loss: 0.8511 - val_accuracy: 0.6632 - val_loss: 1.1208\n",
            "Epoch 20/50\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.7587 - loss: 0.6957\n",
            "Epoch 20: val_accuracy improved from 0.66316 to 0.71579, saving model to /content/drive/MyDrive/mobilenetv3_safe_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 213ms/step - accuracy: 0.7582 - loss: 0.6967 - val_accuracy: 0.7158 - val_loss: 1.0609\n",
            "Epoch 21/50\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 0.7763 - loss: 0.6992\n",
            "Epoch 21: val_accuracy improved from 0.71579 to 0.74737, saving model to /content/drive/MyDrive/mobilenetv3_safe_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 290ms/step - accuracy: 0.7752 - loss: 0.6999 - val_accuracy: 0.7474 - val_loss: 1.0026\n",
            "Epoch 22/50\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - accuracy: 0.8042 - loss: 0.6081\n",
            "Epoch 22: val_accuracy improved from 0.74737 to 0.76842, saving model to /content/drive/MyDrive/mobilenetv3_safe_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 261ms/step - accuracy: 0.8032 - loss: 0.6101 - val_accuracy: 0.7684 - val_loss: 0.9476\n",
            "Epoch 23/50\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 0.7980 - loss: 0.6210\n",
            "Epoch 23: val_accuracy improved from 0.76842 to 0.77895, saving model to /content/drive/MyDrive/mobilenetv3_safe_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 214ms/step - accuracy: 0.7987 - loss: 0.6197 - val_accuracy: 0.7789 - val_loss: 0.8949\n",
            "Epoch 24/50\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.7926 - loss: 0.6004\n",
            "Epoch 24: val_accuracy improved from 0.77895 to 0.82105, saving model to /content/drive/MyDrive/mobilenetv3_safe_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 237ms/step - accuracy: 0.7919 - loss: 0.6010 - val_accuracy: 0.8211 - val_loss: 0.8432\n",
            "Epoch 25/50\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - accuracy: 0.8054 - loss: 0.5762\n",
            "Epoch 25: val_accuracy improved from 0.82105 to 0.84211, saving model to /content/drive/MyDrive/mobilenetv3_safe_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 292ms/step - accuracy: 0.8050 - loss: 0.5766 - val_accuracy: 0.8421 - val_loss: 0.7908\n",
            "Epoch 26/50\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 0.8244 - loss: 0.5563\n",
            "Epoch 26: val_accuracy did not improve from 0.84211\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 194ms/step - accuracy: 0.8237 - loss: 0.5573 - val_accuracy: 0.8421 - val_loss: 0.7408\n",
            "Epoch 27/50\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - accuracy: 0.8117 - loss: 0.5519\n",
            "Epoch 27: val_accuracy did not improve from 0.84211\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 245ms/step - accuracy: 0.8120 - loss: 0.5519 - val_accuracy: 0.8421 - val_loss: 0.6953\n",
            "Epoch 28/50\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 0.8491 - loss: 0.4973\n",
            "Epoch 28: val_accuracy did not improve from 0.84211\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 191ms/step - accuracy: 0.8479 - loss: 0.4985 - val_accuracy: 0.8421 - val_loss: 0.6537\n",
            "Epoch 29/50\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - accuracy: 0.8236 - loss: 0.5070\n",
            "Epoch 29: val_accuracy improved from 0.84211 to 0.86316, saving model to /content/drive/MyDrive/mobilenetv3_safe_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 268ms/step - accuracy: 0.8242 - loss: 0.5058 - val_accuracy: 0.8632 - val_loss: 0.6204\n",
            "Epoch 30/50\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.8469 - loss: 0.4748\n",
            "Epoch 30: val_accuracy did not improve from 0.86316\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 211ms/step - accuracy: 0.8471 - loss: 0.4744 - val_accuracy: 0.8632 - val_loss: 0.5906\n",
            "Epoch 31/50\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.8314 - loss: 0.4681\n",
            "Epoch 31: val_accuracy improved from 0.86316 to 0.87368, saving model to /content/drive/MyDrive/mobilenetv3_safe_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 235ms/step - accuracy: 0.8332 - loss: 0.4663 - val_accuracy: 0.8737 - val_loss: 0.5610\n",
            "Epoch 32/50\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.8703 - loss: 0.4528\n",
            "Epoch 32: val_accuracy improved from 0.87368 to 0.89474, saving model to /content/drive/MyDrive/mobilenetv3_safe_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 265ms/step - accuracy: 0.8704 - loss: 0.4506 - val_accuracy: 0.8947 - val_loss: 0.5282\n",
            "Epoch 33/50\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.8733 - loss: 0.4244\n",
            "Epoch 33: val_accuracy improved from 0.89474 to 0.90526, saving model to /content/drive/MyDrive/mobilenetv3_safe_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 216ms/step - accuracy: 0.8734 - loss: 0.4236 - val_accuracy: 0.9053 - val_loss: 0.5032\n",
            "Epoch 34/50\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - accuracy: 0.8611 - loss: 0.4330\n",
            "Epoch 34: val_accuracy did not improve from 0.90526\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 232ms/step - accuracy: 0.8624 - loss: 0.4303 - val_accuracy: 0.9053 - val_loss: 0.4769\n",
            "Epoch 35/50\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - accuracy: 0.8792 - loss: 0.4139\n",
            "Epoch 35: val_accuracy improved from 0.90526 to 0.91579, saving model to /content/drive/MyDrive/mobilenetv3_safe_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 292ms/step - accuracy: 0.8796 - loss: 0.4115 - val_accuracy: 0.9158 - val_loss: 0.4520\n",
            "Epoch 36/50\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.8981 - loss: 0.3610\n",
            "Epoch 36: val_accuracy improved from 0.91579 to 0.92632, saving model to /content/drive/MyDrive/mobilenetv3_safe_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 217ms/step - accuracy: 0.8980 - loss: 0.3601 - val_accuracy: 0.9263 - val_loss: 0.4316\n",
            "Epoch 37/50\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - accuracy: 0.9209 - loss: 0.3143\n",
            "Epoch 37: val_accuracy did not improve from 0.92632\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 265ms/step - accuracy: 0.9202 - loss: 0.3149 - val_accuracy: 0.9263 - val_loss: 0.4113\n",
            "Epoch 38/50\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.9223 - loss: 0.3101\n",
            "Epoch 38: val_accuracy improved from 0.92632 to 0.93684, saving model to /content/drive/MyDrive/mobilenetv3_safe_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 256ms/step - accuracy: 0.9221 - loss: 0.3102 - val_accuracy: 0.9368 - val_loss: 0.3932\n",
            "Epoch 39/50\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.8959 - loss: 0.3044\n",
            "Epoch 39: val_accuracy improved from 0.93684 to 0.95789, saving model to /content/drive/MyDrive/mobilenetv3_safe_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - accuracy: 0.8963 - loss: 0.3046 - val_accuracy: 0.9579 - val_loss: 0.3746\n",
            "Epoch 40/50\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - accuracy: 0.8999 - loss: 0.3190\n",
            "Epoch 40: val_accuracy did not improve from 0.95789\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 231ms/step - accuracy: 0.8999 - loss: 0.3186 - val_accuracy: 0.9579 - val_loss: 0.3575\n",
            "Epoch 41/50\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 0.9255 - loss: 0.2698\n",
            "Epoch 41: val_accuracy did not improve from 0.95789\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 228ms/step - accuracy: 0.9257 - loss: 0.2694 - val_accuracy: 0.9579 - val_loss: 0.3425\n",
            "Epoch 42/50\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.9244 - loss: 0.2846\n",
            "Epoch 42: val_accuracy did not improve from 0.95789\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 193ms/step - accuracy: 0.9251 - loss: 0.2830 - val_accuracy: 0.9579 - val_loss: 0.3321\n",
            "Epoch 43/50\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - accuracy: 0.9353 - loss: 0.2563\n",
            "Epoch 43: val_accuracy did not improve from 0.95789\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 241ms/step - accuracy: 0.9347 - loss: 0.2572 - val_accuracy: 0.9579 - val_loss: 0.3182\n",
            "Epoch 44/50\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.9121 - loss: 0.2789\n",
            "Epoch 44: val_accuracy did not improve from 0.95789\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 194ms/step - accuracy: 0.9132 - loss: 0.2770 - val_accuracy: 0.9579 - val_loss: 0.3076\n",
            "Epoch 45/50\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - accuracy: 0.9374 - loss: 0.2321\n",
            "Epoch 45: val_accuracy improved from 0.95789 to 0.96842, saving model to /content/drive/MyDrive/mobilenetv3_safe_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 307ms/step - accuracy: 0.9379 - loss: 0.2314 - val_accuracy: 0.9684 - val_loss: 0.2954\n",
            "Epoch 46/50\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.9405 - loss: 0.2349\n",
            "Epoch 46: val_accuracy did not improve from 0.96842\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 191ms/step - accuracy: 0.9402 - loss: 0.2347 - val_accuracy: 0.9579 - val_loss: 0.2852\n",
            "Epoch 47/50\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.9468 - loss: 0.2137\n",
            "Epoch 47: val_accuracy did not improve from 0.96842\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 195ms/step - accuracy: 0.9464 - loss: 0.2137 - val_accuracy: 0.9579 - val_loss: 0.2770\n",
            "Epoch 48/50\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - accuracy: 0.9388 - loss: 0.2135\n",
            "Epoch 48: val_accuracy did not improve from 0.96842\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 240ms/step - accuracy: 0.9391 - loss: 0.2134 - val_accuracy: 0.9579 - val_loss: 0.2689\n",
            "Epoch 49/50\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.9383 - loss: 0.2081\n",
            "Epoch 49: val_accuracy did not improve from 0.96842\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 192ms/step - accuracy: 0.9387 - loss: 0.2072 - val_accuracy: 0.9474 - val_loss: 0.2620\n",
            "Epoch 50/50\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 0.9581 - loss: 0.1914\n",
            "Epoch 50: val_accuracy did not improve from 0.96842\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 191ms/step - accuracy: 0.9574 - loss: 0.1913 - val_accuracy: 0.9474 - val_loss: 0.2552\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9227 - loss: 0.3079\n",
            "\n",
            "FINAL V3 ACCURACY: 91.58%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras import layers, mixed_precision\n",
        "import pandas as pd\n",
        "import os\n",
        "import zipfile\n",
        "from google.colab import drive\n",
        "\n",
        "# --- 1. SETUP (MUST MATCH TRAINING ENVIRONMENT) ---\n",
        "tf.keras.backend.clear_session()\n",
        "# FIX: Re-enable Mixed Precision so the float16 weights load correctly\n",
        "policy = mixed_precision.Policy('mixed_float16')\n",
        "mixed_precision.set_global_policy(policy)\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "test_dir = '/content/dataset/my_clean_cropped_data_splitted_and_resized/test'\n",
        "\n",
        "# --- 2. DEFINE CUSTOM LAYER ---\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "class CoordinateAttention(layers.Layer):\n",
        "    def __init__(self, reduction_ratio=32, **kwargs):\n",
        "        super(CoordinateAttention, self).__init__(**kwargs)\n",
        "        self.reduction_ratio = reduction_ratio\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        channels = input_shape[-1]\n",
        "        reduction_channels = max(8, channels // self.reduction_ratio)\n",
        "        self.conv_reduction = layers.Conv2D(reduction_channels, kernel_size=1, use_bias=False)\n",
        "        self.bn = layers.BatchNormalization()\n",
        "        self.activation = layers.Activation('relu')\n",
        "        self.conv_w = layers.Conv2D(channels, kernel_size=1, use_bias=False)\n",
        "        self.conv_h = layers.Conv2D(channels, kernel_size=1, use_bias=False)\n",
        "        super(CoordinateAttention, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        shape = tf.shape(inputs)\n",
        "        h, w = shape[1], shape[2]\n",
        "        x_h = tf.reduce_mean(inputs, axis=2, keepdims=True)\n",
        "        x_w = tf.reduce_mean(inputs, axis=1, keepdims=True)\n",
        "        x_w_perm = tf.transpose(x_w, perm=[0, 2, 1, 3])\n",
        "        x_cat = tf.concat([x_h, x_w_perm], axis=1)\n",
        "        x_cat = self.activation(self.bn(self.conv_reduction(x_cat)))\n",
        "        x_h_prime, x_w_prime = tf.split(x_cat, num_or_size_splits=[h, w], axis=1)\n",
        "        x_w_prime = tf.transpose(x_w_prime, perm=[0, 2, 1, 3])\n",
        "        att_h = tf.nn.sigmoid(self.conv_w(x_h_prime))\n",
        "        att_w = tf.nn.sigmoid(self.conv_h(x_w_prime))\n",
        "        return inputs * att_h * att_w\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\"reduction_ratio\": self.reduction_ratio})\n",
        "        return config\n",
        "\n",
        "# --- 3. EVALUATION LOOP ---\n",
        "models_paths = {\n",
        "    \"MobileNetV2 (Baseline)\": \"/content/drive/MyDrive/mobilenet_baseline_best.h5\",\n",
        "    \"MobileNetV3 (SOTA)\":     \"/content/drive/MyDrive/mobilenetv3_safe_best.h5\",\n",
        "    \"MobileNetV2 + CA (Ours)\": \"/content/drive/MyDrive/prda_mobilenetv2_final.h5\"\n",
        "}\n",
        "\n",
        "# Raw Test Data\n",
        "raw_test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    test_dir, image_size=(224, 224), batch_size=32, label_mode='categorical', shuffle=False\n",
        ")\n",
        "\n",
        "results = []\n",
        "print(\"\\n--- CALCULATING REAL LOSS ---\")\n",
        "\n",
        "for name, path in models_paths.items():\n",
        "    if not os.path.exists(path):\n",
        "        continue\n",
        "\n",
        "    print(f\"Evaluating {name}...\")\n",
        "    try:\n",
        "        # Load model with Custom Object Scope\n",
        "        with tf.keras.utils.custom_object_scope({'CoordinateAttention': CoordinateAttention}):\n",
        "            model = load_model(path, compile=False) # Skip compile to avoid optimizer mismatch\n",
        "\n",
        "        model.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        # Preprocessing Wrapper\n",
        "        def preprocess(x, y):\n",
        "            # V3 has internal preprocessing, others need manual\n",
        "            if \"MobileNetV3\" in name:\n",
        "                return x, y\n",
        "            else:\n",
        "                return tf.keras.applications.mobilenet_v2.preprocess_input(x), y\n",
        "\n",
        "        loss, acc = model.evaluate(raw_test_ds.map(preprocess), verbose=0)\n",
        "        results.append({\n",
        "            \"Model\": name,\n",
        "            \"Test Loss\": f\"{loss:.4f}\",\n",
        "            \"Accuracy\": f\"{acc*100:.2f}%\"\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error on {name}: {e}\")\n",
        "\n",
        "# --- 4. PRINT TABLE ---\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(pd.DataFrame(results).to_markdown(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbZC8bbRJTtH",
        "outputId": "7ee733b3-bc04-4c49-fb47-8d22cd343482"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Found 95 files belonging to 5 classes.\n",
            "\n",
            "--- CALCULATING REAL LOSS ---\n",
            "Evaluating MobileNetV2 (Baseline)...\n",
            "Evaluating MobileNetV3 (SOTA)...\n",
            "Error on MobileNetV3 (SOTA): Only input tensors may be passed as positional arguments. The following argument value should be passed as a keyword argument: 3.0 (of type <class 'float'>)\n",
            "Evaluating MobileNetV2 + CA (Ours)...\n",
            "\n",
            "========================================\n",
            "| Model                   |   Test Loss | Accuracy   |\n",
            "|:------------------------|------------:|:-----------|\n",
            "| MobileNetV2 (Baseline)  |      0.291  | 93.68%     |\n",
            "| MobileNetV2 + CA (Ours) |      0.2328 | 93.68%     |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, mixed_precision\n",
        "import os\n",
        "import zipfile\n",
        "from google.colab import drive\n",
        "\n",
        "# --- 1. SETUP ---\n",
        "tf.keras.backend.clear_session()\n",
        "# Re-enable mixed precision because the model was trained with it\n",
        "policy = mixed_precision.Policy('mixed_float16')\n",
        "mixed_precision.set_global_policy(policy)\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "test_dir = '/content/dataset/my_clean_cropped_data_splitted_and_resized/test'\n",
        "\n",
        "# --- 2. RE-BUILD V3 EXACTLY AS TRAINED ---\n",
        "def build_mobilenet_v3_safe():\n",
        "    # We must match the training structure 100%\n",
        "    base_model = tf.keras.applications.MobileNetV3Large(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        input_shape=(224, 224, 3),\n",
        "        include_preprocessing=True # This layer handles the 0-255 scaling\n",
        "    )\n",
        "    base_model.trainable = True\n",
        "\n",
        "    inputs = tf.keras.Input(shape=(224, 224, 3))\n",
        "    x = base_model(inputs)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(5, activation='softmax', dtype='float32')(x)\n",
        "\n",
        "    return models.Model(inputs, outputs, name=\"Benchmark_MobileNetV3_Safe\")\n",
        "\n",
        "# --- 3. LOAD WEIGHTS & EVALUATE ---\n",
        "print(\"\\n--- FORCING V3 EVALUATION ---\")\n",
        "\n",
        "# 1. Build blank model\n",
        "model_v3 = build_mobilenet_v3_safe()\n",
        "\n",
        "# 2. Compile (Required for evaluate)\n",
        "model_v3.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 3. Load Weights (Not load_model)\n",
        "# This bypasses the architecture reconstruction bug\n",
        "try:\n",
        "    print(\"Loading weights...\")\n",
        "    model_v3.load_weights(\"/content/drive/MyDrive/mobilenetv3_safe_best.h5\")\n",
        "    print(\"✅ Weights loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Weight load failed: {e}\")\n",
        "\n",
        "# 4. Evaluate\n",
        "# Note: V3 includes preprocessing, so we pass raw images\n",
        "raw_test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    test_dir, image_size=(224, 224), batch_size=32, label_mode='categorical', shuffle=False\n",
        ")\n",
        "\n",
        "loss, acc = model_v3.evaluate(raw_test_ds, verbose=1)\n",
        "\n",
        "print(\"\\n\" + \"=\"*30)\n",
        "print(f\"FINAL V3 LOSS:     {loss:.4f}\")\n",
        "print(f\"FINAL V3 ACCURACY: {acc*100:.2f}%\")\n",
        "print(\"=\"*30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-wLWBlRMRFf",
        "outputId": "9ddb99ad-c302-4235-c3b5-d62a3f7e0de2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "--- FORCING V3 EVALUATION ---\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v3/weights_mobilenet_v3_large_224_1.0_float_no_top_v2.h5\n",
            "\u001b[1m12683000/12683000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Loading weights...\n",
            "✅ Weights loaded successfully.\n",
            "Found 95 files belonging to 5 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer._make_function.<locals>.multi_step_on_iterator at 0x7ccf7f1ed3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 16s/step - accuracy: 0.9227 - loss: 0.3561\n",
            "\n",
            "==============================\n",
            "FINAL V3 LOSS:     0.3659\n",
            "FINAL V3 ACCURACY: 91.58%\n",
            "==============================\n"
          ]
        }
      ]
    }
  ]
}